{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Basic operation in Tensorflow"
      ],
      "metadata": {
        "id": "TqHRpxvSjSsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor Creation:\n",
        "\n",
        "tf.constant(): Create constant tensors\n",
        "Syntax: tf.constant(value, dtype=None, shape=None, name='Const')\n",
        "\n",
        "\n",
        "tf.Variable(): Create mutable tensors that can be updated during training therefore used for the model parameters.\n",
        "Syntax: tf.Variable(initial_value, name=None, dtype=None)\n",
        "\n",
        "\n",
        "tf.zeros(), tf.ones(): Create tensors filled with 0s or 1s\n",
        "\n",
        "\n",
        "tf.random.normal(): Create tensors with random values drawn from a normal distribution.\n"
      ],
      "metadata": {
        "id": "Afi2iEUzjs1a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-HQXDhkH8BX",
        "outputId": "6a12f184-4931-4f9c-a370-9ccec4674a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant Tensor: 5.0\n",
            "Variable Tensor: 5.0\n",
            "Zeros Tensor: [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "Ones Tensor: [[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "Random Normal Tensor: [[ 0.7046776  -0.23545773  0.64569485]\n",
            " [ 0.17530797  1.4227375   0.16837333]\n",
            " [-0.3455063   0.5465385  -0.20086426]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ensure TensorFlow 2.x behavior\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# 1. tf.constant(): Create constant tensors\n",
        "const_tensor = tf.constant(5.0, dtype=tf.float32)\n",
        "print(\"Constant Tensor:\", const_tensor.numpy())\n",
        "\n",
        "# 2. tf.Variable(): Create mutable tensors\n",
        "var_tensor = tf.Variable(5.0, dtype=tf.float32)\n",
        "print(\"Variable Tensor:\", var_tensor.numpy())\n",
        "\n",
        "# 3. tf.zeros(), tf.ones(): Create tensors filled with 0s or 1s\n",
        "zeros_tensor = tf.zeros([3, 3], dtype=tf.float32)\n",
        "ones_tensor = tf.ones([3, 3], dtype=tf.float32)\n",
        "print(\"Zeros Tensor:\", zeros_tensor.numpy())\n",
        "print(\"Ones Tensor:\", ones_tensor.numpy())\n",
        "\n",
        "# 4. tf.random.normal(): Create tensors with random values\n",
        "random_tensor = tf.random.normal([3, 3], mean=0.0, stddev=1.0, dtype=tf.float32)\n",
        "print(\"Random Normal Tensor:\", random_tensor.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical Operations:\n",
        "\n",
        "Addition: tf.add() or '+'\n",
        "\n",
        "\n",
        "Subtraction: tf.subtract() or '-'\n",
        "\n",
        "\n",
        "Multiplication: tf.multiply() or '*'\n",
        "\n",
        "\n",
        "Division: tf.divide() or '/'\n",
        "\n",
        "\n",
        "Matrix multiplication: tf.matmul()\n"
      ],
      "metadata": {
        "id": "H6Knu0rdjvGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ensure TensorFlow 2.x behavior\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# Define tensors\n",
        "a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "b = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
        "\n",
        "# a) Addition\n",
        "add_result_1 = tf.add(a, b)\n",
        "add_result_2 = a + b  # Alternative way\n",
        "print(\"Addition (tf.add):\\n\", add_result_1.numpy())\n",
        "print(\"Addition (+):\\n\", add_result_2.numpy())\n",
        "\n",
        "# b) Subtraction\n",
        "sub_result_1 = tf.subtract(a, b)\n",
        "sub_result_2 = a - b  # Alternative way\n",
        "print(\"Subtraction (tf.subtract):\\n\", sub_result_1.numpy())\n",
        "print(\"Subtraction (-):\\n\", sub_result_2.numpy())\n",
        "\n",
        "# c) Multiplication (element-wise)\n",
        "mul_result_1 = tf.multiply(a, b)\n",
        "mul_result_2 = a * b  # Alternative way\n",
        "print(\"Multiplication (tf.multiply):\\n\", mul_result_1.numpy())\n",
        "print(\"Multiplication (*):\\n\", mul_result_2.numpy())\n",
        "\n",
        "# d) Division (element-wise)\n",
        "div_result_1 = tf.divide(a, b)\n",
        "div_result_2 = a / b  # Alternative way\n",
        "print(\"Division (tf.divide):\\n\", div_result_1.numpy())\n",
        "print(\"Division (/):\\n\", div_result_2.numpy())\n",
        "\n",
        "# e) Matrix multiplication\n",
        "matmul_result = tf.matmul(a, b)\n",
        "print(\"Matrix Multiplication (tf.matmul):\\n\", matmul_result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdVQPLaSIDGH",
        "outputId": "9f89946f-01f8-4064-fcfb-6691ebb1f367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition (tf.add):\n",
            " [[ 6.  8.]\n",
            " [10. 12.]]\n",
            "Addition (+):\n",
            " [[ 6.  8.]\n",
            " [10. 12.]]\n",
            "Subtraction (tf.subtract):\n",
            " [[-4. -4.]\n",
            " [-4. -4.]]\n",
            "Subtraction (-):\n",
            " [[-4. -4.]\n",
            " [-4. -4.]]\n",
            "Multiplication (tf.multiply):\n",
            " [[ 5. 12.]\n",
            " [21. 32.]]\n",
            "Multiplication (*):\n",
            " [[ 5. 12.]\n",
            " [21. 32.]]\n",
            "Division (tf.divide):\n",
            " [[0.2        0.33333334]\n",
            " [0.42857143 0.5       ]]\n",
            "Division (/):\n",
            " [[0.2        0.33333334]\n",
            " [0.42857143 0.5       ]]\n",
            "Matrix Multiplication (tf.matmul):\n",
            " [[19. 22.]\n",
            " [43. 50.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor Manipulation:\n",
        "\n",
        "Reshaping: tf.reshape()\n",
        "\n",
        "\n",
        "Transposing: tf.transpose()\n",
        "\n",
        "\n",
        "Concatenation: tf.concat()\n",
        "\n",
        "\n",
        "Slicing: tensor[start:end]\n"
      ],
      "metadata": {
        "id": "sDSWSrdZkFYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ensure TensorFlow 2.x behavior\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# Define a tensor\n",
        "tensor = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
        "print(\"Original Tensor:\\n\", tensor.numpy())\n",
        "\n",
        "# a) Reshaping: tf.reshape()\n",
        "reshaped_tensor = tf.reshape(tensor, [3, 2])\n",
        "print(\"Reshaped Tensor (2x3 to 3x2):\\n\", reshaped_tensor.numpy())\n",
        "\n",
        "# b) Transposing: tf.transpose()\n",
        "transposed_tensor = tf.transpose(tensor)\n",
        "print(\"Transposed Tensor:\\n\", transposed_tensor.numpy())\n",
        "\n",
        "# c) Concatenation: tf.concat()\n",
        "tensor_a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "tensor_b = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
        "concatenated_tensor = tf.concat([tensor_a, tensor_b], axis=0)  # Concatenate along rows\n",
        "print(\"Concatenated Tensor along rows:\\n\", concatenated_tensor.numpy())\n",
        "\n",
        "concatenated_tensor_1 = tf.concat([tensor_a, tensor_b], axis=1)  # Concatenate along columns\n",
        "print(\"Concatenated Tensor along columns:\\n\", concatenated_tensor_1.numpy())\n",
        "\n",
        "# d) Slicing: tensor[start:end]\n",
        "sliced_tensor = tensor[0:1, 1:3]  # Slice second row and second and third columns\n",
        "print(\"Sliced Tensor (first row, second and third columns):\\n\", sliced_tensor.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sv5PysqIKyx",
        "outputId": "e467de01-e845-4cb8-dfb8-8053ad613545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " [[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "Reshaped Tensor (2x3 to 3x2):\n",
            " [[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n",
            "Transposed Tensor:\n",
            " [[1. 4.]\n",
            " [2. 5.]\n",
            " [3. 6.]]\n",
            "Concatenated Tensor along rows:\n",
            " [[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]\n",
            " [7. 8.]]\n",
            "Concatenated Tensor along columns:\n",
            " [[1. 2. 5. 6.]\n",
            " [3. 4. 7. 8.]]\n",
            "Sliced Tensor (first row, second and third columns):\n",
            " [[2. 3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TensorFlow Data Types\n",
        "\n",
        "a) Numeric Types:\n",
        "- tf.float32, tf.float64: Floating-point numbers\n",
        "- tf.int8, tf.int16, tf.int32, tf.int64: Signed integers\n",
        "- tf.uint8, tf.uint16: Unsigned integers\n",
        "- tf.bool: Boolean values\n",
        "\n",
        "b) String Type:\n",
        "- tf.string: For text data\n",
        "\n",
        "c) Complex Number Types:\n",
        "- tf.complex64, tf.complex128: Complex numbers\n",
        "\n",
        "d) Quantized Types:\n",
        "- tf.qint8, tf.quint8, tf.qint32: For quantized operations\n"
      ],
      "metadata": {
        "id": "jZgCm0mQkJRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# a) Numeric Types:\n",
        "# Floating-point numbers\n",
        "float32_tensor = tf.constant(3.14, dtype=tf.float32)\n",
        "float64_tensor = tf.constant(3.14, dtype=tf.float64)\n",
        "\n",
        "# Signed integers\n",
        "int8_tensor = tf.constant(127, dtype=tf.int8)\n",
        "int16_tensor = tf.constant(32767, dtype=tf.int16)\n",
        "int32_tensor = tf.constant(2147483647, dtype=tf.int32)\n",
        "int64_tensor = tf.constant(9223372036854775807, dtype=tf.int64)\n",
        "\n",
        "# Unsigned integers\n",
        "uint8_tensor = tf.constant(255, dtype=tf.uint8)\n",
        "uint16_tensor = tf.constant(65535, dtype=tf.uint16)\n",
        "\n",
        "# Boolean\n",
        "bool_tensor = tf.constant(True, dtype=tf.bool)\n",
        "\n",
        "# b) String Type:\n",
        "string_tensor = tf.constant(\"Hello, TensorFlow!\", dtype=tf.string)\n",
        "\n",
        "# c) Complex Number Types:\n",
        "complex64_tensor = tf.constant(1 + 2j, dtype=tf.complex64)\n",
        "complex128_tensor = tf.constant(1 + 2j, dtype=tf.complex128)\n",
        "\n",
        "# d) Quantized Types:\n",
        "# These are typically used in specific quantization contexts\n",
        "qint8_tensor = tf.quantization.quantize(tf.constant([-1.0, 0.0, 1.0]), -1.0, 1.0, tf.qint8)\n",
        "quint8_tensor = tf.quantization.quantize(tf.constant([0.0, 1.0, 2.0]), 0.0, 2.0, tf.quint8)\n",
        "qint32_tensor = tf.quantization.quantize(tf.constant([-1.0, 0.0, 1.0]), -1.0, 1.0, tf.qint32)\n",
        "\n",
        "# Print out the tensors to see their values and types\n",
        "print(\"float32:\", float32_tensor)\n",
        "print(\"float64:\", float64_tensor)\n",
        "print(\"int8:\", int8_tensor)\n",
        "print(\"int16:\", int16_tensor)\n",
        "print(\"int32:\", int32_tensor)\n",
        "print(\"int64:\", int64_tensor)\n",
        "print(\"uint8:\", uint8_tensor)\n",
        "print(\"uint16:\", uint16_tensor)\n",
        "print(\"bool:\", bool_tensor)\n",
        "print(\"string:\", string_tensor)\n",
        "print(\"complex64:\", complex64_tensor)\n",
        "print(\"complex128:\", complex128_tensor)\n",
        "print(\"qint8:\", qint8_tensor)\n",
        "print(\"quint8:\", quint8_tensor)\n",
        "print(\"qint32:\", qint32_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekcvcLf-Mlzk",
        "outputId": "15d0614d-002b-4a5f-cb35-1879b758b096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32: tf.Tensor(3.14, shape=(), dtype=float32)\n",
            "float64: tf.Tensor(3.14, shape=(), dtype=float64)\n",
            "int8: tf.Tensor(127, shape=(), dtype=int8)\n",
            "int16: tf.Tensor(32767, shape=(), dtype=int16)\n",
            "int32: tf.Tensor(2147483647, shape=(), dtype=int32)\n",
            "int64: tf.Tensor(9223372036854775807, shape=(), dtype=int64)\n",
            "uint8: tf.Tensor(255, shape=(), dtype=uint8)\n",
            "uint16: tf.Tensor(65535, shape=(), dtype=uint16)\n",
            "bool: tf.Tensor(True, shape=(), dtype=bool)\n",
            "string: tf.Tensor(b'Hello, TensorFlow!', shape=(), dtype=string)\n",
            "complex64: tf.Tensor((1+2j), shape=(), dtype=complex64)\n",
            "complex128: tf.Tensor((1+2j), shape=(), dtype=complex128)\n",
            "qint8: QuantizeV2(output=<tf.Tensor: shape=(3,), dtype=qint8, numpy=array([-128,   -1,  127], dtype=int8)>, output_min=<tf.Tensor: shape=(), dtype=float32, numpy=-1.0>, output_max=<tf.Tensor: shape=(), dtype=float32, numpy=1.0>)\n",
            "quint8: QuantizeV2(output=<tf.Tensor: shape=(3,), dtype=quint8, numpy=array([  0, 128, 255], dtype=uint8)>, output_min=<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, output_max=<tf.Tensor: shape=(), dtype=float32, numpy=2.0>)\n",
            "qint32: QuantizeV2(output=<tf.Tensor: shape=(3,), dtype=qint32, numpy=array([-2147483648,           0, -2147483648], dtype=int32)>, output_min=<tf.Tensor: shape=(), dtype=float32, numpy=-1.0>, output_max=<tf.Tensor: shape=(), dtype=float32, numpy=1.0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating and manipulating matrices in TensorFlow\n",
        "\n",
        "Creating Matrices: Define matrices using tf.constant().\n",
        "\n",
        "Matrix Addition: Use tf.add() or the + operator.\n",
        "\n",
        "Element-wise Multiplication: Use tf.multiply() or the * operator.\n",
        "\n",
        "Matrix Multiplication (Dot Product): Use tf.matmul().\n",
        "\n",
        "Matrix Transpose: Use tf.transpose().\n"
      ],
      "metadata": {
        "id": "XIu4A9RDkvIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Creating matrices\n",
        "matrix_a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "matrix_b = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
        "print(\"Matrix A:\\n\", matrix_a.numpy())\n",
        "print(\"Matrix B:\\n\", matrix_b.numpy())\n",
        "\n",
        "# Matrix addition\n",
        "matrix_add = tf.add(matrix_a, matrix_b)\n",
        "print(\"Matrix Addition:\\n\", matrix_add.numpy())\n",
        "\n",
        "# Matrix multiplication (element-wise)\n",
        "matrix_mul_elementwise = tf.multiply(matrix_a, matrix_b)\n",
        "print(\"Element-wise Multiplication:\\n\", matrix_mul_elementwise.numpy())\n",
        "\n",
        "# Matrix multiplication (dot product)\n",
        "matrix_mul = tf.matmul(matrix_a, matrix_b)\n",
        "print(\"Matrix Multiplication (dot product):\\n\", matrix_mul.numpy())\n",
        "\n",
        "# Matrix transpose\n",
        "matrix_transpose = tf.transpose(matrix_a)\n",
        "print(\"Matrix Transpose:\\n\", matrix_transpose.numpy())\n"
      ],
      "metadata": {
        "id": "3dMS2-ZZvCR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a13581-d78e-473d-8d3b-8450df36704f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            " [[1. 2.]\n",
            " [3. 4.]]\n",
            "Matrix B:\n",
            " [[5. 6.]\n",
            " [7. 8.]]\n",
            "Matrix Addition:\n",
            " [[ 6.  8.]\n",
            " [10. 12.]]\n",
            "Element-wise Multiplication:\n",
            " [[ 5. 12.]\n",
            " [21. 32.]]\n",
            "Matrix Multiplication (dot product):\n",
            " [[19. 22.]\n",
            " [43. 50.]]\n",
            "Matrix Transpose:\n",
            " [[1. 3.]\n",
            " [2. 4.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Matrices: Define matrices using tf.constant().\n",
        "\n",
        "Matrix Addition: Use tf.add() or the + operator.\n",
        "\n",
        "Element-wise Multiplication: Use tf.multiply() or the * operator.\n",
        "\n",
        "Matrix Multiplication (Dot Product): Use tf.matmul().\n",
        "\n",
        "Matrix Transpose: Use tf.transpose()."
      ],
      "metadata": {
        "id": "TdLRMRIqmJPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Operations in TensorFlow\n",
        "\n",
        "Defining a Simple Function: Use standard Python function definition to create operations. In TensorFlow 2.x, these are executed eagerly by default.\n",
        "\n",
        "\n",
        "Using tf.function for Performance Optimization:\n",
        "- Decorate functions with @tf.function to compile them into a static graph for faster execution.\n",
        "- tf.function improves performance by optimizing and parallelizing the execution of operations.\n"
      ],
      "metadata": {
        "id": "_To_5n8_mRfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple function\n",
        "def simple_operation(a, b):\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# Using tf.function for performance optimization\n",
        "@tf.function\n",
        "def optimized_operation(a, b):\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# Sample inputs\n",
        "a = tf.constant(10)\n",
        "b = tf.constant(20)\n",
        "\n",
        "# Execute operations\n",
        "result_simple = simple_operation(a, b)\n",
        "result_optimized = optimized_operation(a, b)\n",
        "\n",
        "print(\"Simple Operation Result:\", result_simple.numpy())\n",
        "print(\"Optimized Operation Result:\", result_optimized.numpy())\n"
      ],
      "metadata": {
        "id": "Ob2R-18rvCZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e114f722-d0ca-4e87-f563-f13db3883462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Operation Result: 30\n",
            "Optimized Operation Result: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Layering Nested Operations\n",
        "Creating Complex Operations by Nesting Functions"
      ],
      "metadata": {
        "id": "AnS4DDx9mlui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define nested functions\n",
        "def add_and_multiply(a, b):\n",
        "    add_result = tf.add(a, b)\n",
        "    mul_result = tf.multiply(a, b)\n",
        "    return add_result, mul_result\n",
        "\n",
        "# Higher-level function that uses the nested function\n",
        "def complex_operation(x, y, z):\n",
        "    add_mul_result = add_and_multiply(x, y)\n",
        "    final_result = tf.subtract(add_mul_result[0], z)\n",
        "    return final_result\n",
        "\n",
        "# Sample inputs\n",
        "x = tf.constant(5)\n",
        "y = tf.constant(3)\n",
        "z = tf.constant(2)\n",
        "\n",
        "# Execute the complex operation\n",
        "result = complex_operation(x, y, z)\n",
        "print(\"Complex Operation Result:\", result.numpy())\n"
      ],
      "metadata": {
        "id": "EJ5O1NVYvCb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7ae428-dea7-4c27-a47d-1eefd9956619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex Operation Result: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nested Functions: Create reusable operations by nesting functions.\n",
        "\n",
        "Higher-Level Functions: Organize code by using higher-level functions that call nested functions."
      ],
      "metadata": {
        "id": "bn9A57dfmsa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Practices for Organizing Code:\n",
        "\n",
        "Modularity: Break down complex operations into smaller, reusable functions.\n",
        "\n",
        "Readability: Use meaningful function names and comments to improve code readability.\n",
        "\n",
        "Maintainability: Organize functions logically to make the code easier to maintain and extend."
      ],
      "metadata": {
        "id": "6v-uS-f2mwBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Executing Computational Graphs in TensorFlow\n",
        "TensorFlow allows you to build and execute computational graphs. With TensorFlow 2.x, eager execution is enabled by default, making it easier to develop and debug models. However, you can still build and execute static computational graphs using @tf.function for performance optimization. Here’s a detailed look at both approaches:"
      ],
      "metadata": {
        "id": "LTOv1e5owFoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple operation with eager execution (dynamic graph)\n",
        "def simple_operation(a, b):\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# Define the same operation with @tf.function for static graph execution\n",
        "@tf.function\n",
        "def optimized_operation(a, b):\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# Sample inputs\n",
        "a = tf.constant(10)\n",
        "b = tf.constant(20)\n",
        "\n",
        "# Execute operations\n",
        "result_simple = simple_operation(a, b)\n",
        "result_optimized = optimized_operation(a, b)\n",
        "\n",
        "print(\"Simple Operation Result:\", result_simple.numpy())         # Eager execution\n",
        "print(\"Optimized Operation Result:\", result_optimized.numpy())   # Static graph execution\n"
      ],
      "metadata": {
        "id": "Ut0VRxCeZlBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Eager Execution (Dynamic Graphs)\n",
        "Eager execution allows operations to be executed immediately, providing a more intuitive and interactive way to build and test your models.\n",
        "\n"
      ],
      "metadata": {
        "id": "q94LATjBwNcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable eager execution (default in TensorFlow 2.x)\n",
        "print(\"Eager execution:\", tf.executing_eagerly())\n",
        "\n",
        "# Define tensors\n",
        "a = tf.constant(2.0)\n",
        "b = tf.constant(3.0)\n",
        "\n",
        "# Perform operations\n",
        "c = a + b\n",
        "d = a * b\n",
        "\n",
        "# Print results\n",
        "print(\"Addition result (eager execution):\", c.numpy())\n",
        "print(\"Multiplication result (eager execution):\", d.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wBmC4vtwILx",
        "outputId": "87879b99-b3f5-4096-e627-4b7d04f47e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eager execution: True\n",
            "Addition result (eager execution): 5.0\n",
            "Multiplication result (eager execution): 6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Static Graphs (Using @tf.function)\n",
        "Static graphs allow TensorFlow to optimize and parallelize the execution of operations, improving performance for repeated executions.\n",
        "\n",
        "Example: Static Graph Execution with @tf.function"
      ],
      "metadata": {
        "id": "IC4OCLWCwQQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a function using tf.function to create a static graph\n",
        "@tf.function\n",
        "def compute_operations(a, b):\n",
        "    c = tf.add(a, b)\n",
        "    d = tf.multiply(a, b)\n",
        "    return c, d\n",
        "\n",
        "# Define tensors\n",
        "a = tf.constant(2.0)\n",
        "b = tf.constant(3.0)\n",
        "\n",
        "# Execute operations\n",
        "c, d = compute_operations(a, b)\n",
        "\n",
        "# Print results\n",
        "print(\"Addition result (static graph):\", c.numpy())\n",
        "print(\"Multiplication result (static graph):\", d.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3G-7mXwPLd",
        "outputId": "7496a082-80dd-4381-b339-5ad35e58a928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition result (static graph): 5.0\n",
            "Multiplication result (static graph): 6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Activation Functions\n"
      ],
      "metadata": {
        "id": "FgTbC28spl9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation functions are mathematical functions used in neural networks to introduce non-linearity into the model. They are a critical component because they enable neural networks to learn and represent complex patterns. Without activation functions, a neural network would simply be a linear regression model, regardless of the number of layers.\n"
      ],
      "metadata": {
        "id": "tiSmUZhXpsPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ensure TensorFlow 2.x behavior\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# Define a sample tensor\n",
        "tensor = tf.constant([-1.0, 0.0, 1.0], dtype=tf.float32)\n",
        "print(\"Original Tensor:\\n\", tensor.numpy())\n",
        "\n",
        "# a) ReLU (Rectified Linear Unit): tf.nn.relu()\n",
        "relu_tensor = tf.nn.relu(tensor)\n",
        "print(\"ReLU Applied:\\n\", relu_tensor.numpy())\n",
        "\n",
        "# b) Sigmoid: tf.nn.sigmoid()\n",
        "sigmoid_tensor = tf.nn.sigmoid(tensor)\n",
        "print(\"Sigmoid Applied:\\n\", sigmoid_tensor.numpy())\n",
        "\n",
        "# c) Tanh (Hyperbolic Tangent): tf.nn.tanh()\n",
        "tanh_tensor = tf.nn.tanh(tensor)\n",
        "print(\"Tanh Applied:\\n\", tanh_tensor.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQriyWk6JYf7",
        "outputId": "aa4d7361-15cb-48c5-c434-26a0de3bdc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " [-1.  0.  1.]\n",
            "ReLU Applied:\n",
            " [0. 0. 1.]\n",
            "Sigmoid Applied:\n",
            " [0.26894143 0.5        0.7310586 ]\n",
            "Tanh Applied:\n",
            " [-0.7615942  0.         0.7615942]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Neural Networks with Multiple Layers\n",
        "\n"
      ],
      "metadata": {
        "id": "BaIN__ppm2F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(32, activation='relu', input_shape=(64,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ic5H_gJZvCex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e191ccb-8436-4d75-d52e-5edad22bf4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4842 (18.91 KB)\n",
            "Trainable params: 4842 (18.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Sequential API: Use tf.keras.Sequential to stack layers in a linear manner.\n",
        "\n",
        "Dense Layers: Define fully connected layers with tf.keras.layers.Dense."
      ],
      "metadata": {
        "id": "YkQZvVN3m8Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using tf.keras to Simplify Layer Management"
      ],
      "metadata": {
        "id": "CqLYjvd8m_S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define a more complex model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Adding layers incrementally\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8QUAe1InCh1",
        "outputId": "317da852-63fc-410b-db36-bc1c1233cbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4842 (18.91 KB)\n",
            "Trainable params: 4842 (18.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "- Layer Management: Add layers incrementally to a tf.keras.Sequential model.\n",
        "- Model Summary: Use model.summary() to display the model architecture and parameters."
      ],
      "metadata": {
        "id": "H94FH9y2nFTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Points:\n",
        "- Layering Nested Operations: Create complex operations by nesting functions and organizing code for readability and maintainability.\n",
        "- Working with Multiple Layers: Build neural networks with multiple layers using tf.keras, leveraging the Sequential API to simplify layer management."
      ],
      "metadata": {
        "id": "ME7P0IR-nK71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Loss Functions\n",
        "\n",
        "Common Loss Functions"
      ],
      "metadata": {
        "id": "wtoXcazsncwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE"
      ],
      "metadata": {
        "id": "jG9ScHN9b0Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example usage of MSE\n",
        "y_true = tf.constant([1.0, 2.0, 3.0])\n",
        "y_pred = tf.constant([1.1, 2.1, 2.9])\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "loss = mse(y_true, y_pred)\n",
        "print(\"MSE Loss:\", loss.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2y4wmNcwPfh",
        "outputId": "3e241e0b-e123-4468-dd1f-fb9d86e6f5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Loss: 0.009999989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical Cross-Entropy"
      ],
      "metadata": {
        "id": "xXhu3x5Cb24u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example usage of Categorical Cross-Entropy\n",
        "y_true = tf.constant([[0, 1, 0], [0, 0, 1]])\n",
        "y_pred = tf.constant([[0.05, 0.95, 0.0], [0.1, 0.8, 0.1]])\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "loss = cce(y_true, y_pred)\n",
        "print(\"Categorical Cross-Entropy Loss:\", loss.numpy())\n"
      ],
      "metadata": {
        "id": "5BJMhNyBb5Y2",
        "outputId": "915c6543-8aa2-406f-aa07-0c3ad5631d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Cross-Entropy Loss: 1.1769392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Custom Loss Functions"
      ],
      "metadata": {
        "id": "FYLKVeAab27D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "\n",
        "# Example usage of custom loss function\n",
        "y_true = tf.constant([1.0, 2.0, 3.0])\n",
        "y_pred = tf.constant([1.1, 2.1, 2.9])\n",
        "loss = custom_loss_function(y_true, y_pred)\n",
        "print(\"Custom Loss:\", loss.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGknH0Bb1YW",
        "outputId": "ff761b1f-a442-4e9f-90db-251325112c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Loss: 0.09999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Mean Squared Error (MSE): Measures the average squared difference between the predicted and actual values.\n",
        "\n",
        "Categorical Cross-Entropy: Measures the difference between two probability distributions for classification tasks.\n",
        "\n",
        "Custom Loss Functions: Define a custom loss function by creating a function that takes true labels and predictions as input and returns a scalar loss value."
      ],
      "metadata": {
        "id": "r4YBm1xqnjEi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T85g7Bamb-a8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}